---
title: "Week 7 Simple Linear Regression"
output: html_document
date: "2025-09-30"
editor_options: 
  chunk_output_type: console
---

Set up workspace: 
```{r, eval=FALSE}
library(pwr)
library(effectsize) 
library(tidyverse)
library(ggplot2)
library(glmmTMB) # for regression
library(DHARMa) #for checking model fit
library(emmeans) # for post-hoc effects
library(lubridate) # for dates

setwd("PSY705/lessons/week7") #set your working directory 

load("Hyenas.RData") #load the hyenas tibble already cleaned/formatted 

```

## 1. A priori power analysis for correlations

From our long-term database we found a significant negative correlation between standardized rank and age at first parturition of -0.34. 

We want to do a study where we look at rank's effect on age at first parturition with hyenas in Botswana which live in much smaller clans at lower density due to the harsher living conditions. Does rank still have such a big effect? How many hyenas do we need to sample if there's a smaller effect? 



```{r, eval=FALSE}

effectSize <- -0.20   # anticipated correlation (small effect size)


# 🚨 POLL: If we reduce our expected effect size from r = -0.34 to r = -0.20,
# do we need:
#   a) More hyenas 
#   b) Fewer hyenas 
#   c) The same number


# A priori power analysis: how many Botswana female hyenas do we need to detect r = 0.34?
pwr.r.test(r = effectSize,
           sig.level = 0.05,   # alpha
           power = 0.80,       # desired power
           alternative = "less")

#calculates an n of 152.42 = 153 hyenas 

#we need to measure 153 females in order to have an 80% chance of detecting a small negative correlation in botwsana hyenas between rank and age at first parturition 



```


## 2. A priori power analysis for t-test

Next, from our long-term database we found a non-significant effect of sex
If there IS a true difference, what sample size would we need to detect it in a second field season? 

```{r, eval=FALSE}
cohens_d(ageGrad ~ sex, data = hyenas)

# A priori power analysis: how many hyenas do we need to detect a significant difference?
pwr.t.test(d = .11,
           sig.level = 0.05,   # alpha
           power = 0.80,       # desired power
           type = "one.sample",
           alternative = "two.sided")
```

651 hyenas **PER GROUP**, so over 1000 total 
If there isn't a true difference we are unlikely to detect it even with 1000 hyenas. 

Note: Power analyses should be done **a priori!** (before the fact)
If your p-value is significant a post-hoc power test will always say you had sufficient power and if you p-value is not significant a post-hoc power test will always say you didn't have enough power (if you use your measured effect size). 

With a large enough sample size even tiny differences become significant, this is why effect size is just as important as p-values. And with small sample sizes even large effects may be non-significant. 
```{r, eval=FALSE}
set.seed(121)

# Tiny effect size
x <- 0.01
sd <- 1

# Try different sample sizes
sample_sizes <- c(10, 100, 1000, 10000, 100000)

#what is our p-value if we randomly sample different size n's from the population? 
for (n in sample_sizes) {
  x <- rnorm(n, mean = x, sd = sd)
  t_result <- t.test(x, mu = 0)
  cat("N =", n, " | t =", round(t_result$statistic, 3),
      " | p =", signif(t_result$p.value, 3), "\n")
}

pwr.t.test(d = x/sd,
           sig.level = 0.05,   # alpha
           power = 0.80,       # desired power
           type = "one.sample",
           alternative = "two.sided")
#recomended is ~78,500 so this explains why we got a significant p-value with 100,000 samples. 
#but an effect size of .01 (when sd is 1) is so close to zero that this might not be biologically meaningful (and I would doubt it is truly different from zero).


# 🚨 THINK-PAIR-SHARE: Why do tiny effects become statistically significant
# with huge N, but may not be scientifically meaningful?


```



## 3. Correlation vs Regression
```{r, eval=FALSE}

# Example data: heights (inches) and weights (pounds)
height <- c(60, 62, 65, 67, 70, 72, 75)
weight <- c(115, 120, 140, 150, 175, 185, 210)

# 1. Correlation
cor.test(height, weight)

# correlation tells us about the strength of the relationship between variables (no line fitted)

# 2. Equation for a simple straight line (y=mx+b or Y = b0 + b1*X)
# regression tells us about the "line of best fit" 

# Calculate slope (b1) and intercept (b0) manually
n <- length(height)
mean_x <- mean(height)
mean_y <- mean(weight)

# Slope: b1 = sum((x - x̄)*(y - ȳ)) / sum((x - x̄)^2)
b1 <- sum((height - mean_x) * (weight - mean_y)) / sum((height - mean_x)^2)
b1

# 🚨 THINK-PAIR-SHARE: We found slope = 6.45. How do you interpret this in words?
# (e.g., “for each 1 inch increase in height, weight increases by ___ lbs”)


# Intercept: b0 = ȳ - b1*x̄
b0 <- mean_y - b1 * mean_x
b0  # intercept

# 🚨 POLL: What does the intercept mean here?
#   a) Predicted weight for someone of average height
#   b) Predicted weight when height = 0
#   c) The average of X and Y

# Step 2: Predicted values
predictedWeight <- b0 + b1 * height
predictedWeight
weight
#this line does a pretty good job predicting weights! 

# Step 3: Residuals
residuals <- weight - predicted
residuals

#now we have all our regression estimates
#yi = b0 + b1*xi + ei 

weight #yi= weight
b0 #point estimate (no sub i) for intercept
b1 #point estimate for slope
height #x=height
residuals #residual error (1 for each value of xi)
predicted # y-hat where y-hat = b0 + b1*xi

#raw data plus predicted as a line 
plot(height, weight) #plot raw data (x,y)
points(height, predicted, col="red") #plot the predicted data (x,y-hat)
abline(a = b0, b = b1, col="red")  #plot the regression line (connect predicted points) 
for(i in 1:length(height)){ #add residuals 
  segments(x0 = height[i], y0 = weight[i], 
           x1 = height[i], y1 = predicted[i], 
           col = "blue")
}

#how much error is there in the model? how much variation is NOT explained by a simple straight line 

# Checking assumptions
# 1. Homogeneity of variance: residuals all have roughly the same variance across all fitted (predicted) values of y (error is roughly equal across X values)

plot(predictedWeight, residuals)  # look for roughly horizontal band of points
abline(h=0, col="red")

# 2. Independence of Observations: no observation linked to others, all from different subjects for example 

# 3. Normality: Residuals themselves should be normally distributed (around 0)
# Lots of small errors on either side of the regression line and some larger errors should create a normal distribution 
hist(residuals)
qqnorm(residuals)
qqline(residuals)


# Step 4: Compare with lm()
model <- lm(weight ~ height)
summary(model)


plot(height, weight, main="Height vs Weight",
     xlab="Height (inches)", ylab="Weight (pounds)", pch=19)
abline(model, col="blue", lwd=2)

#view the intercept
plot(height, weight, main="Height vs Weight",
     xlab="Height (inches)", ylab="Weight (pounds)", pch=19, xlim=c(0,76), ylim=c(-300, 200))
abline(model, col="blue", lwd=2)





# Step 5: Centering predictor variables  

#center the data around the mean (mean for X becomes 0)

# Centering
height_c <- height - mean(height)

# Note: We typically only center predictors because we want the response variable to remain easily interpretable 

# Fit regression with centered height
model_c <- lm(weight ~ height_c)
summary(model_c)

#same slope for X
#different intercept (now the intercept is the weight at average height)

plot(height_c, weight, main="Height vs Weight",
     xlab="Height (inches above or below the mean height of 67.29 inches)", ylab="Weight (pounds)", pch=19)
abline(model_c, col="blue", lwd=2)
abline(h=model_c$coefficients[1], col="red")
abline(v=0, col="red")
#plot is virtually identical we've just shifted the scale for height

summary(model_c)
#p-values for intercept and slope 

#residual standard error: this is essentially the average size of the residuals, i.e., how far observed weights are from the predicted weights, in original units (pounds). Smaller is better. 

#R-squared: Here: 98.93% of the variation in weight is explained by height. Always between 0 and 1 — closer to 1 = strong linear relationship. 
#multiple: Proportion of the total variance in the response variable (Y) explained by the predictors.
#adjusted: Same as multiple but adjusted for multiple predictor (X) variables. With only 1 predictor it should be nearly identical to multiple. 

#F-stat: 460.5 = ratio of variance explained by model / variance left unexplained.
# F > 1 → the model explains more variance than is left over; the larger it is, the stronger the evidence that the predictor matters.
# F < 1 → the model explains less variance than the residual noise; the predictor is essentially worse than guessing the mean.

#p-value for model is basically the same as p-value for height because we have only one predictor, once we get into multiple regression this p-value is basically the combined/global effect of the whole model at fitting the data. E.g., do all predictors together explain variance in Y? 



```



## 3. Rank and Lifespan

Do high ranking hyenas live longer? 
H0: There is no effect of rank on lifespan. 
H1: There is an effect of rank on lifespan. 
Response variable: Lifespan
Predictor: Rank 
```{r, eval=FALSE}

#create a filtered dataset for this analysis
hyenasLife <- hyenas %>% drop_na(stan_rank, lifespan) %>% filter(sex=="f")
#remove the missing values and also include only females, since males often disappear/disperse and we don't know what their true lifespan is 

#LOOK AT THE DATA
hist(hyenasLife$stan_rank) # x does not need to be normal
hist(hyenasLife$lifespan) #y does not need to be normal 

#HOWEVER, if y is very skewed or bounded, a linear regression may give weird residuals and poor model fit 

# Check assumptions 
# 1. Linear relationship 
ggplot(hyenasLife, aes(x=stan_rank, y=lifespan)) + 
  geom_point(alpha=.5) + 
  geom_smooth(method="loess", color="red") + 
  geom_smooth(method="lm", color="blue")

# 2. Independence of observations (yes, each from a unique hyena)
# BUT, some hyenas are closely related which DOES mean they're not truly independent... but our sample is fairly large and includes many hyenas from different clans that are all unrelated, so all the high ranking hyenas are NOT related so any bias should be limited 

# 3. Fit the model 
lifespanModel <- glmmTMB(lifespan ~ stan_rank, data=hyenasLife)
summary(lifespanModel)

# 🚨 RECAP: What does the estimate and p-value for the intercept mean? 
# 🚨 RECAP: What does the estimate and p-value for rank mean? 

#intercept is 2.38, this means that for mid-ranking hyenas (x=0) average lifespan is 2.38 years, the significant p-value means it is significantly different from zero 
#slope for rank is 0.86, this means that for each one unit increase in x, say from 0 (mid) to top-ranking (1) hyeans live almost one year longer, the significant p-value suggests this increase is significantly different from a slope of 0

qqnorm(resid(lifespanModel))
qqline(resid(lifespanModel), col = "red")

plot(fitted(lifespanModel), resid(lifespanModel),
     xlab = "Fitted values",
     ylab = "Residuals",
     main = "Residuals vs Fitted")
abline(h = 0, col = "red")
#fitted = the predicted y values
#residausl = error associated with each value 

# 🚨 POLL: Look at this residuals vs fitted plot. Which assumption is being tested?
#   a) Linearity
#   b) Homoscedasticity (equal variance)
#   c) Normality of residuals
#   d) Independence


res1 <- simulateResiduals(lifespanModel, plot = TRUE)
#these residuals aren't great... let's take a look at what all this red actually means... 

#for this data set, I would investigate transforming lifespan or using a different model beyond simple linear regression
```

## 4. Log-transformation of the response variable: Rank and log(Lifespan)
```{r, eval=FALSE}
hist(log(hyenas$lifespan)) #roughly normal on log transformation 
#A log-transformation spreads out values near 0 but compresses values far away.

values <- c(.5, 1,2,3,4,5)
log(values)

values2 <- c(1,10,20,30,40,100,1000,10000)
log(values2)

plot(values2)
plot(log(values2))

ggplot(hyenasLife, aes(x=stan_rank, y=log(lifespan))) + 
  geom_point(alpha=.5) + 
  geom_smooth(method="loess", color="red") + 
  geom_smooth(method="lm", color="blue")

lifespanModel2 <- glmmTMB(log(lifespan) ~ stan_rank, data=hyenasLife)
summary(lifespanModel2)

# If you log-transform Y: coefficients are interpreted in terms of percent changes, not raw units.

# The coefficient (0.298) is on the log scale. Exponentiating gives exp(0.298) ≈ 1.35.
# This means: for each 1-unit increase in rank, lifespan is multiplied by ~1.35 (a 35% increase).

# Since rank goes from -1 to 1, that’s a 2-unit spread. Going from the lowest (-1) to the highest (1) rank would multiply lifespan by exp(0.298 × 2) ≈ exp(0.596) ≈ 1.82 → an 82% longer lifespan.

simulateResiduals(lifespanModel2, plot = TRUE)
#looks beautiful! 
#note the outliers show up in both the residuals and our scatter plot. 

#Plot result
predict(lifespanModel2) #predicted values for y

ggplot(data=hyenasLife, aes(x=stan_rank, y=log(lifespan))) + geom_point() + #raw data as points
  geom_line(aes(x=stan_rank, y=predict(lifespanModel2)), color="red", linewidth=1) #predicted data as a line

hyenasLife <- hyenasLife %>% mutate(predicted=predict(lifespanModel2)) #mutate a new column with predicted values so that you have them saved in the dataframe 
ggplot(data=hyenasLife, aes(x=stan_rank, y=predicted)) + geom_point() #plot the predicted points 


```

## 5. Does age at den graduation predict age at weaning? 
Another example: 
Most cubs graduate from the den first, but keep nursing from mom. Does leaving earlier correspond to weaning earlier? 
```{r, eval=FALSE}
#look at the data
hist(hyenas$ageWeaning)
hist(hyenas$ageGrad)

hyenaSubs <- hyenas %>% drop_na(ageWeaning, ageGrad)
hist(hyenaSubs$ageWeaning)
hist(hyenaSubs$ageGrad)


#fit the model
m2 <- glmmTMB(ageWeaning ~ ageGrad, data=hyenas)
summary(m2)


#normality of residuals
qqnorm(resid(m2))
qqline(resid(m2), col = "red")

#residuals vs fitted
plot(fitted(m2), resid(m2))

#with dharma
res2 <- simulateResiduals(m2, plot = TRUE)
#looks great! Just a few red outliers




```


## 4. t-test... ANOVA... It’s linear regression all the way down!
We can use all three to compare age at graduation to sex and they are mathematically identical, just with different estimates extracted.  
*If you square the value of t from a t-test, you get the F-value*.
*lm output gives us the F-statistic which is identical to the F-value*

```{r, eval=FALSE}
t.test(ageGrad ~ sex, data=hyenas) #t-test
 
summary(aov(ageGrad ~ sex, data=hyenas)) #anova

1.3588^2 #if you square the value of t from a t-test you get the F-value

summary(lm(ageGrad~sex, data=hyenas)) #simple linear regression 

#the math is basically identical, just different output for different ways of asking a question


```



## 5. Regression with a categorical predictor 
Does lifespan differ among clans? 
```{r, eval=FALSE}
#look at the data 
hist(hyenas$lifespan)
ggplot(hyenas, aes(x=lifespan, fill=clan)) + geom_density(alpha=.5)

#make talek the first (reference) variable as it's in a different management than the other three 
hyenas$clan <- relevel(hyenas$clan, ref="talek")

#create the model 
m3 <- glmmTMB(lifespan ~ clan, data=hyenas)
summary(m3)

#with dharma
res3 <- simulateResiduals(m3, plot = TRUE)
plot(res3)

#same as with ANOVA we need a post-hoc test to see where differences are
#we know all three clans are different from talek, but are any of them different from each other? 

library(emmeans)
emmeans(m3, pairwise ~ clan) #pairwise comparisons
emmeans(m3, ~clan) #descriptive stats per clan


#is this driven by more hyenas living longer or less hyenas dying young? juvenile vs adult survival?! 
hyenasAdults <- hyenas %>% filter(lifespan > 2)
hist(hyenasAdults$lifespan)
ggplot(hyenasAdults, aes(x=lifespan, fill=clan)) + geom_density(alpha=.5)

#create the model 
m4 <- glmmTMB(lifespan ~ clan, data=hyenasAdults)
summary(m4)
emmeans(m4, ~clan) #descriptive stats per clan
emmeans(m4, pairwise ~ clan) #pairwise comparisons

#with dharma
res4 <- simulateResiduals(m4, plot = TRUE)


```


No class next week. 
Second quiz the week after! 